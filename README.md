# Flappy Bird Neural Netword

Projeto desenvolvido por [Igor Andrade](https://github.com/andradeigor). Este projeto foi feito como projeto final da disciplina Computa√ß√£o Cient√≠fica e An√°lise de Dados, consiste na implementa√ß√£o de uma rede neural treinada via algoritmo gen√©tico para jogar Flappy Bird.

- [Teoria](#üñã-teoria)
- [Implementa√ß√£o](#üíª-implementa√ß√£o)
- [Como Usar](#ü§ñ-como-usar)
- [Demonstra√ß√£o](#üìú-demonstra√ß√£o)
- [Tecnologias](#üíª-tecnologias)
- [Contribuidores](#üë•-contribuidores)
- [Licen√ßa](#üìñ-licen√ßa)

## üñã Teoria:

Para entender esse projeto precisamos primeiro ter em mente as partes que o comp√µem. Uma parte importante do c√≥digo √© feita via um algoritmo de Template Matching, usando o biblioteca OpenCV2. Esse algoritmo foi implementado e explicado por mim no trabalho final da disciplina [√Ålgebra Linear Algor√≠tmica](https://github.com/andradeigor/CosineMatcher) e est√° sendo usado nesse projeto para detectar e localizar o p√°ssaro e os canos do jogo Flappy Bird.

Com essa informa√ß√£o em m√£os, passamos esses dados para uma Rede Neural que foi implementada do zero, seguindo o seguinte modelo:

![image-2](https://github.com/andradeigor/CosineMatcher/assets/21049910/5b077f70-f4fa-4e78-982f-826e0ca14a62)

Dentro de uma rede neural, n√≥s temos esse n√≥s de entrada que passam a informa√ß√£o que ser√° analizada. No nosso caso, os dados de entrada s√£o a localiza√ß√£o do p√°ssaro e dos canos. Ap√≥s esses dados chegarem na camada de entrada eles s√£o processados pelas camadas internas (hidden layers) e chegam no neur√¥nio de sa√≠da da rede neural, que nos d√° um valor entre [0-1], dependendo do valor que n√≥s foi dado, n√≥s realizamos ou n√£o uma a√ß√£o dentro do jogo.

Na realidade, o que est√° acontecendo na rede neural √© que todos os neur√¥nios das camadas anteriores s√£o conectados aos neur√¥nios da camada seguinte e s√£o usados para gerar seus valores. Para melhor vizualiza√ß√£o, tome como exemplo o neur√¥nio $n_{11}$ da imagem acima, ele possui uma liga√ß√£o com $\{a_1,a_2,a_3\}$ por meio das conex√µes $\{w_1,w_2,w_3\}$. Assim, o que ocorre matematicamente falando √© que o valor de $n_{11}$ √© calculado da seguinte maneira:

$$n_{11} = a_1.w_1+a_2.w_2+a_3.w3$$

Al√©m disso, outro detalhe associado √† cada neur√¥nio √© que cada um deles possuem um valor especial associado chamado de bias, que √© somado ao final de todo c√°lculo feito. Assim, completando o exemplo acima temos:

$$n_{11} = a_1.w_1+a_2.w_2+a_3.w3+b_{11}$$

Esse valor especial em conjunto com os $w_i$ servem para determinar qual ser√° o resultado de cada neur√¥nio dependendo de cada entrada. Indo mais a fundo matematicamente falando, os $w_i$ s√£o os pesos que cada entrada recebe no valor final, e o bias √© um valor que desloca o resultado gerado por essa conta.

Ap√≥s esse c√°lculo ser realizado para um neur√¥nio, ao inv√©s de pegarmos esse resultado e passar para frente, √© adicionaddo mais um tratamento para esse valor gerado: uma fun√ß√£o de ativa√ß√£o √© usada nesse valor, e o resultado dessa fun√ß√£o √© passado como entrada para a pr√≥xima cada, e assim os valroes v√£o caminhando pela rede neural.

![image](https://github.com/andradeigor/CosineMatcher/assets/21049910/4945954c-6b02-4fa4-acd7-160ad5be0da3)

Acima, temos um exemplo da fun√ß√£o de ativa√ß√£o usada nesse projeto $y=tanh(x)$. Perceba que ao usarmos uma fun√ß√£o de ativa√ß√£o, n√≥s padronizamos os poss√≠veis resultados de cada neur√¥nio, n√£o permitindo que eles cres√ßam indefinidamente, sempre nos gerando um resultado entre [-1,1]. Al√©m disso, ao usarmos uma fun√ß√£o de ativa√ß√£o ganha-se o poder de modelar sistemas n√£o lineares dentro de uma rede neural, j√° que agora o c√°lculo da rede inteira n√£o mais pode ser definido como um som√°t√≥rio de fun√ß√µes lineares com pesos.

Com isso, finalmente podemos descrever realmente o c√°lculo que ocorre em cada um dos neur√¥nios:

$$n_{11} = tanh(a_1.w_1+a_2.w_2+a_3.w3+b_{11})$$

Generalizando o c√°lculo acima, temos:

$$n_{ij} = act((\sum_{k=1}^N a_{k}.w_{kj}) +  b_{ij})$$

Onde $N$ √© o n√∫mero de neur√¥nios na camada anterior, $w_{kj}$ s√£o os pesos associados aos neur√¥nios anteriores $a_k$, $b_{ij}$ √© o bias asssociado com o neur√¥nio $n_{ij}$ e act √© a fun√ß√£o de ativa√ß√£o escolhida.

## üìú Demonstra√ß√£o:

## üíª Tecnologias

- Python
- OpenCV
- Pygame
- mss
- pynput

## üë• Contribuidores

Esses s√£o os contribuidores do projeto (<a href="https://allcontributors.org/docs/en/emoji-key">emoji key</a>).

<table>
  <tr>
    <td align="center"><a href="https://github.com/andradeigor"><img style="border-radius: 50%;" src="https://avatars.githubusercontent.com/u/21049910?v=4" width="100px;" alt=""/><br /><sub><b>Igor Andrade</b></sub></a><br /><a href="https://github.com/andradeigor/DiscordBotUFRJ/commits?author=andradeigor" title="Igor Andrade">ü§î üíª üöß</a></td>
  </tr>
</table>

## üìñ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa <a href="https://choosealicense.com/licenses/mit/">MIT</a>.
